{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import json\n",
        "\n",
        "# Load SQL data\n",
        "# Assuming the SQL file contains data creation and insertion queries\n",
        "conn = sqlite3.connect('structured_data.db')  # You can use any SQL database (MySQL, PostgreSQL)\n",
        "\n",
        "# Drop the table if it exists\n",
        "conn.execute('DROP TABLE IF EXISTS structured_data')\n",
        "\n",
        "# Execute the SQL queries to create and insert the data\n",
        "with open('structured_data.sql', 'r') as file:\n",
        "    sql_queries = file.read()\n",
        "\n",
        "conn.executescript(sql_queries)\n",
        "\n",
        "            # Now load the data into a pandas DataFrame\n",
        "df_sql = pd.read_sql('SELECT * FROM structured_data', conn)\n",
        ""
      ],
      "metadata": {
        "id": "qjISTTW2gFxE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load JSON data\n",
        "with open('/content/unstructured_data.json', 'r') as file:\n",
        "    df_json = pd.json_normalize(json.load(file))"
      ],
      "metadata": {
        "id": "sW5dwZhOgB09"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sql['score'] = df_sql['score'].fillna(df_sql['score'].mean())\n"
      ],
      "metadata": {
        "id": "9cRAIApegf7a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a regex pattern to extract the date from the log column\n",
        "df_json['log'] = df_json['log'].str.extract(r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})')[0]\n",
        "\n",
        "# Convert the extracted date strings to datetime format\n",
        "df_json['log'] = pd.to_datetime(df_json['log'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "bjLnkguugjvN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing dates with a placeholder (optional)\n",
        "df_json['log'].fillna(pd.to_datetime('2025-01-01'), inplace=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ywEuVI8gUz9",
        "outputId": "f2459e40-e696-4ca4-951a-58aa67b19f44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-99f9622ee338>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_json['log'].fillna(pd.to_datetime('2025-01-01'), inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two DataFrames on a common field (user_id and log_id)\n",
        "merged_df = pd.merge(df_sql, df_json, how='inner', left_on='user_id', right_on='log_id')\n",
        "\n",
        "# Save the merged DataFrame to a CSV file\n",
        "merged_df.to_csv('merged_data.csv', index=False)\n",
        "\n",
        "# Optionally, download the CSV file in Google Colab\n",
        "from google.colab import files\n",
        "files.download('merged_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "jxL55kvWgXFX",
        "outputId": "83db7637-8e9e-4d39-a493-b7204cc3cca1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90ebffde-f0b6-458c-91c1-9eb5eb0f24f0\", \"merged_data.csv\", 1940)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hWUyWKRsgr0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}